using System;
using System.Collections.Generic;
using System.Diagnostics;
using System.IO;
using System.Linq;
using System.Text;
using System.Text.RegularExpressions;

/*
 *  Loop:
 *  -A <- best attribute
 *  -Assign A as decision attribute for Node
 *  -For each value of A
 *      Create a descendent of node
 * 
 *  -sort training examples to leaves
 *  -if examples perfectly classified STOP
 *      else iterate over leaves 
 * 
 * 
 *  S = set of training examples
 *  A = particular attribute?
 *  Gain(S,A) = Entropy (S) - average entropy over each set of examples you have over a particular value   
 * 
 * */


namespace AiAssignment4
{
    struct Data
    {
        public string label;
        public string[] attributeValues;
    }

    struct Feature
    {
        public string name;
        public string[] values;
        public int index;
    }


    class Node
    {
        public Feature feature;
        public Node[] branches;

        public bool decision;
        public bool end;

    }

    class Program
    {

        static Feature[] features;
        static Data[] dataSet;

        static void Main(string[] args)
        {

            try
            {
                List<string> fileContents = new List<string>();
                ReadFile("mydata.txt", ref fileContents);  
                //ReadFile("test-titanic-fatalities.data", ref fileContents);


                features = new Feature[int.Parse(fileContents[2])];
                List<string> examples = new List<string>();
                string[] classLabels = { fileContents[0], fileContents[1] };
        

                for (int i = 3, k = 0; i < features.Length + 3; i++, k++)   //input file has number of features at index 2, so we start populating features array at index of 3
                {
                    string[] featureSplit = fileContents[i].Split(' ');
                    features[k].name = featureSplit[0];
                    features[k].values = new string[featureSplit.Length - 1];
                    features[k].index = k;

                    for (int j = 0; j < features[k].values.Length; j++) features[k].values[j] = featureSplit[j + 1];
                }

                int exampleCount = int.Parse(fileContents[features.Length + 3]);
                for (int i = features.Length + 4; i < fileContents.Count(); i++) examples.Add(fileContents[i]);


                var sw = new Stopwatch();
                sw.Start();

                dataSet = new Data[examples.Count()];
                for (int i = 0; i < examples.Count(); i++)
                {
                    RegexOptions options = RegexOptions.None;
                    Regex regex = new Regex("[ ]{2,}", options);
                    string temp = examples[i].Replace("\t"," ");
                    temp = regex.Replace(temp, " ");
     
                    string[] dataSplit = temp.Split(' ');

                    dataSet[i].label = dataSplit[1];
                    dataSet[i].attributeValues = new string[features.Length];

                    for(int j = 2, attribIndex=0; j < dataSplit.Length; j++,attribIndex++) dataSet[i].attributeValues[attribIndex] = dataSplit[j];

                }

                long elapsedMilliseconds = sw.ElapsedMilliseconds; sw.Stop();


                int plusCount = dataSet.Where(n => n.label.Equals(classLabels[0])).Count();
                int negCount = dataSet.Where(n => n.label.Equals(classLabels[1])).Count();
                float entropy = Entropy(plusCount, negCount, plusCount + negCount);
                float entropyDecision = entropy;

                List<float> attributeEntropy = new List<float>();


                for(int i = 0; i < features.Length; i++)
                {
                    float Gain = 0;
                    for (int featureIndex = 0; featureIndex < features[i].values.Length; featureIndex++)
                    {
                        plusCount = dataSet.Where(n => (n.label.Equals(classLabels[0])) && (n.attributeValues[i].Equals(features[i].values[featureIndex])) ).Count();
                        negCount = dataSet.Where(n => (n.label.Equals(classLabels[1])) && (n.attributeValues[i].Equals(features[i].values[featureIndex]))).Count();
                        int count = plusCount + negCount;

                        float var_a = (-((float)negCount / (float)count) * (float)Math.Log((float)negCount / (float)count, 2));
                        float var_b = ((float)plusCount / (float)count) * (float)Math.Log((float)plusCount / (float)count, 2);
                        if (float.IsNaN(var_a)) var_a = 0;
                        if (float.IsNaN(var_b)) var_b = 0;
                        entropy = var_a - var_b;

                        Gain -= ((float)count/(float)dataSet.Count() * entropy);
                    }


                    Gain += entropyDecision;
                    attributeEntropy.Add(Gain);
                }

                int maxIndex = 0;
                float max = -100;
                for(int i = 0; i < attributeEntropy.Count(); i++) //root index 
                    if (attributeEntropy[i] > max)
                    {
                        max = attributeEntropy[i];
                        maxIndex = i;
                    }

                Node root = new Node
                {
                    feature = features[maxIndex]
                };

                root.branches = new Node[root.feature.values.Length];
                Node currentNode = root;


                //List<Feature> remainingFeatues = new List<Feature>(features);
                //remainingFeatues.Remove(features[maxIndex]);

                var isRunning = true;

                var tempDataset = dataSet;

                int tempIndex = 0;

                while (isRunning)
                { //start while

                    List<bool> toggles =  new List<bool>();

                    currentNode.branches = new Node[currentNode.feature.values.Length];

                    for (int i = 0; i < currentNode.feature.values.Length; i++)
                    {
                        if (currentNode.end) continue;


                        //first check if all yes or all no.     in dataset the labels in the 0th index = yes, 1st index = no
                        plusCount = tempDataset.Where(n => (n.label.Equals(classLabels[0])) && (n.attributeValues[currentNode.feature.index].Equals(currentNode.feature.values[i]))).Count();
                        negCount = tempDataset.Where(n => (n.label.Equals(classLabels[1])) && (n.attributeValues[currentNode.feature.index].Equals(currentNode.feature.values[i]))).Count();
                        int count = plusCount + negCount;
                        if (plusCount == count)
                        {
                            //currentNode.decision = true;
                            Node n = new Node
                            {
                                feature = currentNode.feature,
                                end = true,
                                decision = true
                            };
                            root.branches[i] = n;
                            toggles.Add(true);
                            continue;
                        }
                        if (negCount == count)
                        {
                            //currentNode.decision = false;
                            Node n = new Node
                            {
                                feature = currentNode.feature,
                                end = true,
                                decision = false
                            };

                            root.branches[i] = n;
                            toggles.Add(true);
                            continue;
                        }

                        toggles.Add(false);
                        entropyDecision = Entropy(plusCount, negCount, count);


                        var filteredList = tempDataset.Where(n => n.attributeValues[currentNode.feature.index].Equals(currentNode.feature.values[i])).ToList();

                        float maxGain = 0;
                        Feature chosenFeature = new Feature();

                        foreach (var f in features)
                        {
                            if (f.name.Equals(currentNode.feature.name)) continue;

                            float Gain = 0;

                            foreach (var element in f.values)
                            {


                                plusCount = filteredList.Where(n => (n.label.Equals(classLabels[0])) &&
                                (n.attributeValues[f.index].Equals(element))).Count();

                                negCount = filteredList.Where(n => (n.label.Equals(classLabels[1])) &&
                                (n.attributeValues[f.index].Equals(element))).Count();

                                count = plusCount + negCount;

                                float var_a = (-((float)negCount / (float)count) * (float)Math.Log((float)negCount / (float)count, 2));
                                float var_b = ((float)plusCount / (float)count) * (float)Math.Log((float)plusCount / (float)count, 2);
                                if (float.IsNaN(var_a)) var_a = 0;
                                if (float.IsNaN(var_b)) var_b = 0;
                                entropy = var_a - var_b;
                                Gain -= ((float)count / (float)filteredList.Count() * entropy);

                            }

                            Gain += entropyDecision;

                            if (Gain >= maxGain)
                            {
                                maxGain = Gain;
                                chosenFeature = f;
                            }
                        }

                        //root.branches[i] = new Node { feature = chosenFeature };
                        currentNode.branches[i] = new Node { feature = chosenFeature };


                        Console.WriteLine("");
                    }

                    if (!toggles.Contains(false)) isRunning = false;

                    currentNode = currentNode.branches[tempIndex++];


                    //tempDataset = tempDataset.Where(n => n.attributeValues[currentNode.feature.index].Equals(currentNode.feature.values[i])).ToList();


                } //end while



                

                Console.WriteLine("ijou desu yo. jikan wa: " + elapsedMilliseconds);


            }
            catch(Exception e) //exception handling out of scope
            {
                Console.WriteLine("Invalid input file");
            }
        }


        static void Find(Node currentNode, string[] classLabels)
        {
            for (int i = 0; i < currentNode.feature.values.Length; i++)
            {
                //first check if all yes or all no.     in dataset the labels in the 0th index = yes, 1st index = no
                int plusCount = dataSet.Where(n => (n.label.Equals(classLabels[0])) && (n.attributeValues[currentNode.feature.index].Equals(currentNode.feature.values[i]))).Count();
                int negCount = dataSet.Where(n => (n.label.Equals(classLabels[1])) && (n.attributeValues[currentNode.feature.index].Equals(currentNode.feature.values[i]))).Count();
                int count = plusCount + negCount;
                if (plusCount == count)
                {
                    currentNode.decision = true;
                    continue;
                }
                if (negCount == count)
                {
                    currentNode.decision = false;
                    continue;
                }

                float entropyDecision = Entropy(plusCount, negCount, count);


                var filteredList = dataSet.Where(n => n.attributeValues[currentNode.feature.index].Equals(currentNode.feature.values[i])).ToList();

                float maxGain = 0;
                Feature chosenFeature = new Feature();

                foreach (var f in features)
                {
                    if (f.name.Equals(currentNode.feature.name)) continue;

                    float Gain = 0;

                    foreach (var element in f.values)
                    {


                        plusCount = filteredList.Where(n => (n.label.Equals(classLabels[0])) &&
                        (n.attributeValues[f.index].Equals(element))).Count();

                        negCount = filteredList.Where(n => (n.label.Equals(classLabels[1])) &&
                        (n.attributeValues[f.index].Equals(element))).Count();

                        count = plusCount + negCount;

                        float var_a = (-((float)negCount / (float)count) * (float)Math.Log((float)negCount / (float)count, 2));
                        float var_b = ((float)plusCount / (float)count) * (float)Math.Log((float)plusCount / (float)count, 2);
                        if (float.IsNaN(var_a)) var_a = 0;
                        if (float.IsNaN(var_b)) var_b = 0;
                        float entropy = var_a - var_b;
                        Gain -= ((float)count / (float)filteredList.Count() * entropy);

                    }

                    Gain += entropyDecision;

                    if (Gain >= maxGain)
                    {
                        maxGain = Gain;
                        chosenFeature = f;
                    }
                }

                //root.branches[i] = new Node { feature = chosenFeature };

                Console.WriteLine("");
            }


        }



        static float Entropy(int positiveCount, int negativeCount, int count)
        {

            return (-((float)positiveCount / (float)count) * (float)Math.Log((float)positiveCount / (float)count, 2))
                - ((float)negativeCount / (float)count) * (float)Math.Log((float)negativeCount / (float)count, 2);
        }

        static bool ReadFile(string fileName, ref List<string> output)
        {
            try
            {
                string dir = Directory.GetCurrentDirectory() + "\\_data\\" + fileName, line;
                StreamReader file = new System.IO.StreamReader(dir);
                List<string> lines = new List<string>();

                while ((line = file.ReadLine()) != null) if(line.Length != 0 && line[0]!='/') lines.Add(line);
                
                file.Close();
                output = lines;
            }
            catch (Exception e)
            {
                if (e.Message != null) Console.WriteLine("Error reading data file: " + e.Message);
                return false;
            }
            return true;
        }


    }

}



------------------------------ 3:30 am version november 11
using System;
using System.Collections.Generic;
using System.Diagnostics;
using System.IO;
using System.Linq;
using System.Text;
using System.Text.RegularExpressions;

/*
 *  Loop:
 *  -A <- best attribute
 *  -Assign A as decision attribute for Node
 *  -For each value of A
 *      Create a descendent of node
 * 
 *  -sort training examples to leaves
 *  -if examples perfectly classified STOP
 *      else iterate over leaves 
 * 
 * 
 *  S = set of training examples
 *  A = particular attribute?
 *  Gain(S,A) = Entropy (S) - average entropy over each set of examples you have over a particular value   
 * 
 * */


namespace AiAssignment4
{
    struct Data
    {
        public string label;
        public string[] attributeValues;
    }

    struct Feature
    {
        public string name;
        public string[] values;
        public int index;
    }


    class Node
    {
        public Feature feature;
        public Node[] branches;

        public bool decision;
        public bool end;

    }

    class Program
    {

        static Feature[] features;
        static Data[] dataSet;

        static void Main(string[] args)
        {

            try
            {
                List<string> fileContents = new List<string>();
                //ReadFile("mydata.txt", ref fileContents);
                ReadFile("train-titanic-fatalities.data", ref fileContents);


                features = new Feature[int.Parse(fileContents[2])];
                List<string> examples = new List<string>();
                string[] classLabels = { fileContents[0], fileContents[1] };


                for (int i = 3, k = 0; i < features.Length + 3; i++, k++)   //input file has number of features at index 2, so we start populating features array at index of 3
                {
                    string[] featureSplit = fileContents[i].Split(' ');
                    features[k].name = featureSplit[0];
                    features[k].values = new string[featureSplit.Length - 1];
                    features[k].index = k;

                    for (int j = 0; j < features[k].values.Length; j++) features[k].values[j] = featureSplit[j + 1];
                }

                int exampleCount = int.Parse(fileContents[features.Length + 3]);
                for (int i = features.Length + 4; i < fileContents.Count(); i++) examples.Add(fileContents[i]);


                var sw = new Stopwatch();
                sw.Start();

                dataSet = new Data[examples.Count()];
                for (int i = 0; i < examples.Count(); i++)
                {
                    RegexOptions options = RegexOptions.None;
                    Regex regex = new Regex("[ ]{2,}", options);
                    string temp = examples[i].Replace("\t", " ");
                    temp = regex.Replace(temp, " ");

                    string[] dataSplit = temp.Split(' ');

                    dataSet[i].label = dataSplit[1];
                    dataSet[i].attributeValues = new string[features.Length];

                    for (int j = 2, attribIndex = 0; j < dataSplit.Length; j++, attribIndex++) dataSet[i].attributeValues[attribIndex] = dataSplit[j];

                }

                


                int plusCount = dataSet.Where(n => n.label.Equals(classLabels[0])).Count();
                int negCount = dataSet.Where(n => n.label.Equals(classLabels[1])).Count();
                float entropy = Entropy(plusCount, negCount, plusCount + negCount);
                float entropyDecision = entropy;

                List<float> attributeEntropy = new List<float>();


                for (int i = 0; i < features.Length; i++)
                {
                    float Gain = 0;
                    for (int featureIndex = 0; featureIndex < features[i].values.Length; featureIndex++)
                    {
                        plusCount = dataSet.Where(n => (n.label.Equals(classLabels[0])) && (n.attributeValues[i].Equals(features[i].values[featureIndex]))).Count();
                        negCount = dataSet.Where(n => (n.label.Equals(classLabels[1])) && (n.attributeValues[i].Equals(features[i].values[featureIndex]))).Count();
                        int count = plusCount + negCount;

                        float var_a = (-((float)negCount / (float)count) * (float)Math.Log((float)negCount / (float)count, 2));
                        float var_b = ((float)plusCount / (float)count) * (float)Math.Log((float)plusCount / (float)count, 2);
                        if (float.IsNaN(var_a)) var_a = 0;
                        if (float.IsNaN(var_b)) var_b = 0;
                        entropy = var_a - var_b;

                        Gain -= ((float)count / (float)dataSet.Count() * entropy);
                    }


                    Gain += entropyDecision;
                    attributeEntropy.Add(Gain);
                }

                int maxIndex = 0;
                float max = -100;
                for (int i = 0; i < attributeEntropy.Count(); i++) //root index 
                    if (attributeEntropy[i] > max)
                    {
                        max = attributeEntropy[i];
                        maxIndex = i;
                    }

                Node root = new Node //treeroot
                {
                    feature = features[maxIndex]
                };

                root.branches = new Node[root.feature.values.Length];
                Node currentNode = root;

                var isRunning = true;

                List<Data> tempDataset = new List<Data>(dataSet);

                int tempIndex = 0;

                List<Node> tempBranchLayer = null;
                bool isCurrentLayerDoneProcessing = true;

                List<string> tempvals = null;
                List<Node> tempAllNodesCurrentLayer = null;

                while (isRunning)
                { //start while

                    if(currentNode.branches == null) currentNode.branches = new Node[currentNode.feature.values.Length];

                    for (int i = 0; i < currentNode.feature.values.Length; i++)
                    {
                        if (currentNode.end) goto endpoint;

                        //first check if all yes or all no.     in dataset the labels in the 0th index = yes, 1st index = no
                        plusCount = tempDataset.Where(n => (n.label.Equals(classLabels[0])) && (n.attributeValues[currentNode.feature.index].Equals(currentNode.feature.values[i]))).Count();
                        negCount = tempDataset.Where(n => (n.label.Equals(classLabels[1])) && (n.attributeValues[currentNode.feature.index].Equals(currentNode.feature.values[i]))).Count();
                        int count = plusCount + negCount;
                        if (plusCount == count)
                        {
                            Node n = new Node
                            {
                                feature = currentNode.feature,
                                end = true,
                                decision = true
                            };
                            currentNode.branches[i] = n;
                            goto endpoint;
                        }
                        if (negCount == count)
                        {
                            Node n = new Node
                            {
                                feature = currentNode.feature,
                                end = true,
                                decision = false
                            };

                            currentNode.branches[i] = n;
                            goto endpoint;
                        }

                        entropyDecision = Entropy(plusCount, negCount, count);


                        var filteredList = tempDataset.Where(n => n.attributeValues[currentNode.feature.index].Equals(currentNode.feature.values[i])).ToList();

                        float maxGain = 0;
                        Feature chosenFeature = new Feature();

                        foreach (var f in features)
                        {
                            if (f.name.Equals(currentNode.feature.name)) continue;

                            float Gain = 0;

                            foreach (var element in f.values)
                            {


                                plusCount = filteredList.Where(n => (n.label.Equals(classLabels[0])) &&
                                (n.attributeValues[f.index].Equals(element))).Count();

                                negCount = filteredList.Where(n => (n.label.Equals(classLabels[1])) &&
                                (n.attributeValues[f.index].Equals(element))).Count();

                                count = plusCount + negCount;

                                float var_a = (-((float)negCount / (float)count) * (float)Math.Log((float)negCount / (float)count, 2));
                                float var_b = ((float)plusCount / (float)count) * (float)Math.Log((float)plusCount / (float)count, 2);
                                if (float.IsNaN(var_a)) var_a = 0;
                                if (float.IsNaN(var_b)) var_b = 0;
                                entropy = var_a - var_b;
                                Gain -= ((float)count / (float)filteredList.Count() * entropy);

                            }

                            Gain += entropyDecision;

                            if (Gain >= maxGain)
                            {
                                maxGain = Gain;
                                chosenFeature = f;
                            }
                        }

                        currentNode.branches[i] = new Node { feature = chosenFeature };

                        endpoint:


                        if(i == currentNode.feature.values.Length - 1 && !isCurrentLayerDoneProcessing)
                        {
                            if (currentNode.branches.Length > 0 && !currentNode.end)
                            {
                                if(tempAllNodesCurrentLayer!=null)
                                    tempAllNodesCurrentLayer.AddRange(currentNode.branches);
                                else
                                    tempAllNodesCurrentLayer = new List<Node>(currentNode.branches);

                            }
                        }

                        if (i == currentNode.feature.values.Length - 1 && isCurrentLayerDoneProcessing)
                        {
                            isCurrentLayerDoneProcessing = false;

                            tempvals = new List<string>(currentNode.feature.values);

                            if(tempAllNodesCurrentLayer!=null)
                            {
                                tempBranchLayer = new List<Node>(tempAllNodesCurrentLayer);
                                tempBranchLayer.AddRange(currentNode.branches);
                            }
                            else
                                tempBranchLayer = new List<Node>(currentNode.branches);

                        }
                        

                    }

                    currentNode = tempBranchLayer[tempIndex];

                    int tempIndex2 = 0;
                    bool tempFlag = false;

                    for(int i = 0; i < features.Length; i++)
                    {
                        for(int j = 0; j < features[i].values.Length; j++)
                        {
                            int val2 = tempIndex;
                            if (tempIndex >= tempvals.Count())
                                val2 = tempvals.Count()-1;
                            if (features[i].values[j].Equals(tempvals[val2]))
                            {
                                tempIndex2 = i;
                                tempFlag = true;
                                break;
                            }
                        }

                        if (tempFlag) break;
                    }

                    int val = tempIndex;
                    if (val > tempvals.Count()) val = tempvals.Count() - 1;
                    tempDataset = dataSet.Where(n => n.attributeValues[tempIndex2].Equals(tempvals[val])).ToList();
                    tempIndex++;
                    

                    bool allDone = true;
                    foreach(var node in tempBranchLayer)
                    {
                        if (!node.end) allDone = false;
                    }


                    if (tempIndex >= tempBranchLayer.Count())
                    {
                        currentNode = tempBranchLayer[tempBranchLayer.Count()-1];
                        tempIndex = 0;
                        isCurrentLayerDoneProcessing = true;

                        tempBranchLayer.Clear();

                    }

                    if (allDone)
                    {
                        isRunning = false;
                    }

                } //end while




                long elapsedMilliseconds = sw.ElapsedMilliseconds; sw.Stop();

                TraverseTree(root);

                Console.WriteLine("ijou desu yo. jikan wa: " + elapsedMilliseconds);


            }
            catch (Exception e) //exception handling out of scope
            {
                Console.WriteLine("Invalid input file");
            }
        }


        static void TraverseTree(Node node)
        {



        }

        static float Entropy(int positiveCount, int negativeCount, int count)
        {

            return (-((float)positiveCount / (float)count) * (float)Math.Log((float)positiveCount / (float)count, 2))
                - ((float)negativeCount / (float)count) * (float)Math.Log((float)negativeCount / (float)count, 2);
        }

        static bool ReadFile(string fileName, ref List<string> output)
        {
            try
            {
                string dir = Directory.GetCurrentDirectory() + "\\_data\\" + fileName, line;
                StreamReader file = new System.IO.StreamReader(dir);
                List<string> lines = new List<string>();

                while ((line = file.ReadLine()) != null) if (line.Length != 0 && line[0] != '/') lines.Add(line);

                file.Close();
                output = lines;
            }
            catch (Exception e)
            {
                if (e.Message != null) Console.WriteLine("Error reading data file: " + e.Message);
                return false;
            }
            return true;
        }


    }

}


